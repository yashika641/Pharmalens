 
# ğŸ§¬ PharmaLens â€“ Smart Medicine Recognition & Misuse Prevention

> A privacy-first, offline-capable AI assistant that identifies medicines from pill strips, verifies usage instructions, and warns against drug interactions â€” powered by vision + LLMs.

---

## ğŸ©º Why PharmaLens?

In many rural and elderly populations, medicine misuse occurs due to:

- Similar-looking pills or packaging
- Inability to read labels (due to literacy or language barriers)
- Lack of access to verified pharmaceutical info

**PharmaLens** aims to solve this using AI + computer vision + NLP.

---

## ğŸ” Features

âœ… Pill & Strip Scanner (Image Input)  
âœ… OCR (Read Printed Labels)  
âœ… Drug Verification (Name, Manufacturer, Type)  
âœ… Correct Dosage Display  
âœ… Drug Interaction Checker (for multiple meds)  
âœ… Voice/Text Prompt with LLM (Gemma 3n via Ollama)  
âœ… Offline Use Capability  
âœ… Batch Scanning of Multiple Pills  
âœ… Confidence Scoring + Retry if Needed  
âœ… "Ask a Pharmacist" AI Mode (LLM fallback)  
âœ… Built-in Safety Warnings & Alert System

---

## ğŸ§  Tech Stack

| Module                | Tool/Tech                          |
|----------------------|------------------------------------|
| OCR                  | Tesseract + OpenCV                 |
| LLM                  | Gemma 3n (Ollama Local Deployment) |
| Backend              | FastAPI / Streamlit                |
| UI                   | Streamlit                          |
| Dataset              | Local JSON/CSV Drug DB (Custom)    |
| Image Processing     | OpenCV, PIL                        |

---

## ğŸš€ Project Structure

```

pharmalens/
â”œâ”€â”€ main.py                  # Entry point (Streamlit/FastAPI)
â”œâ”€â”€ ocr/
â”‚   â””â”€â”€ ocr\_utils.py         # OCR + preprocessing
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ gemma\_prompts.py     # LLM interaction logic
â”œâ”€â”€ data/
â”‚   â””â”€â”€ drugs\_db.csv         # Drug data
â”œâ”€â”€ static/
â”‚   â””â”€â”€ sample\_pill.jpg      # Sample images
â”œâ”€â”€ app/
â”‚   â””â”€â”€ components/          # UI elements
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Installation

```bash
# 1. Clone the repo
git clone https://github.com/yourusername/pharmalens.git
cd pharmalens

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run main.py
````

---

## ğŸ“¸ Sample Usage

1. Upload pill strip image
2. OCR extracts label
3. AI confirms medicine
4. Shows dosage, interaction warnings
5. Optional LLM query: *â€œCan I take this with aspirin?â€*

---

## ğŸ’¬ Example Prompt (to Gemma)

```text
"This pill says 'Paracetamol 500mg'. Can I take this with Ibuprofen? Are there any interaction risks for a 65-year-old diabetic patient?"
```

---

## ğŸ”’ Privacy-First Design

* No cloud storage of images
* LLM runs locally via [Ollama](https://ollama.com/)
* Drug data stored offline

---

## ğŸ¤– Future Additions

* Voice input (speech-to-text)
* Multilingual support
* Real pharmacist API integration (optional)
* Integration with government health DBs (India, WHO, etc.)

---

## ğŸ“¬ Contribute

Got a better OCR model or Indian medicine dataset? PRs welcome!

---
## ğŸ‘¥ Team

Meet the creators behind **PharmaLens**:

|     Name        |          Role                 |                                     GitHub / LinkedIn                                                      |
|-----------------|-------------------------------|------------------------------------------------------------------------------------------------------------|
| Yashika Pal     | Lead Developer & AI Engineer  | [GitHub](https://github.com/yashika641) / [LinkedIn](www.linkedin.com/in/-yashika-pal-)                    |
| Prince Kaushal  | Fullstack Developer           | [GitHub](https://github.com/prince-kaushal01) / [LinkedIn](www.linkedin.com/in/prince-kaushal-473630350)   |

> ğŸ¤ Open to collaborations â€” reach out if youâ€™d like to contribute!


---

## ğŸ“„ License

MIT License Â© 2025 
